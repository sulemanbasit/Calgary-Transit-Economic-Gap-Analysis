{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install matplotlib\n",
    "# !pip3 install tabula-py\n",
    "# !pip3 install PyPDF2\n",
    "# !pip3 install pdfminer.six\n",
    "# !pip3 install PyMuPDF\n",
    "# !pip3 install camelot-py\n",
    "# !pip3 install --upgrade pip\n",
    "# !pip3 install geopandas\n",
    "# !pip3 install plotly\n",
    "# !pip3 install pandas\n",
    "# !pip3 install pdfplumber\n",
    "# !pip3 install scipy\n",
    "# !pip3 install --upgrade pandas\n",
    "# %pip install arcgis\n",
    "# !pip3 install json\n",
    "# !pip3 install gtfs_functions\n",
    "# !pip3 install keplergl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpt\n",
    "import os\n",
    "# import PyPDF2\n",
    "# import tabula\n",
    "# import tabulate\n",
    "# import pdfminer\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "from glob import glob\n",
    "import plotly.express as px\n",
    "from shapely.geometry import Point, MultiPolygon\n",
    "# from shapely import wkt\n",
    "# import pdfplumber\n",
    "# import scipy\n",
    "# import json\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features.analysis import summarize_within\n",
    "from gtfs_functions import Feed\n",
    "from gtfs_functions.gtfs_plots import map_gdf\n",
    "# import keplergl as kpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_to_csv(df, output_folder, file_name):\n",
    "    \"\"\"AI is creating summary for save_to_csv\n",
    "\n",
    "    Args:\n",
    "        df (Pandas Data Frame): Contains data frame that needs to be converted and saved as csv\n",
    "        output_folder (Str): Destination path where df needs to be saved\n",
    "        file_name (Str): File name that df needs to be saved as\n",
    "    \"\"\"\n",
    "    # Check if the output folder exists, if not, create it\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(output_folder, file_name)\n",
    "    \n",
    "    # Save the DataFrame to CSV in the output folder\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    print(f\"DataFrame saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data (file_path):\n",
    "    \"\"\"\n",
    "    Function to convert files of appropriate structure to csv format, creating point object with files that have lat and lon values\n",
    "\n",
    "    Args:\n",
    "        file_path (str): File Path to open and convert to csv file format\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    output_folder_path = os.getcwd()+\"/Data Sets/Analysis Data/\"\n",
    "    # print(output_folder_path)\n",
    "    output_file_name = file_path.split('/')[-1].split('.')[0] + \".csv\"\n",
    "    # output_destination = os.path.join(output_folder_path, output_file_name)\n",
    "    # if 'lat' in str(df.columns) and 'lon' in str(df.columns):\n",
    "    #     lat = \"\"\n",
    "    #     lon = \"\"\n",
    "    #     for col in df.columns:\n",
    "    #         if str(col).endswith('lat'):\n",
    "    #             lat = str(col)\n",
    "    #         elif str(col).endswith('lon'):\n",
    "    #             lon = str(col)\n",
    "    #     df_geo = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[lat],df[lon]))\n",
    "    #     if not os.path.exists(output_folder_path):\n",
    "    #         os.make_dir(output_folder_path)\n",
    "    #     # df_geo.drop(columns=[lat, lon]).to_csv(output_destination, index = False)\n",
    "    #     final_df = df_geo.drop(columns=[lat, lon])\n",
    "    #     save_to_csv(final_df, output_folder_path, output_file_name)\n",
    "    #     print(\"{} saved in {}\".format(output_file_name, output_folder_path))\n",
    "    # else:\n",
    "    # df.to_csv(output_destination, index=False)\n",
    "    save_to_csv(df, output_folder_path, output_file_name)\n",
    "    print(\"{} saved in {}\".format(output_file_name, output_folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd()+\"/Data Sets/CT_GTFS/\"\n",
    "# ignore_file = ['agency.txt', \"calendar.txt\",\"calendar_dates.txt\"]\n",
    "convert_data(data_path+\"shapes.txt\")\n",
    "# Loop through files in the folder\n",
    "# for filename in os.listdir(data_path):\n",
    "#     # print(filename)\n",
    "#     file_path = data_path + filename\n",
    "#     if os.path.isfile(file_path) and filename not in ignore_file:\n",
    "#         try:\n",
    "#             with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#                 # Assuming text files, read the content\n",
    "#                 content = file.read()\n",
    "#                 # Do something with the content\n",
    "#                 convert_data(content)\n",
    "#         except UnicodeDecodeError:\n",
    "#             print(\"Error decoding file:\", file_path)\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program To Calculate Demand Index Using Z-Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_data_path = os.getcwd()+\"/Data Sets/Analysis Data/Community Profiles Compiled.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df = pd.read_excel(community_data_path)\n",
    "# comm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = os.getcwd()+\"/Data Sets/Analysis Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-Score method manually\n",
    "pop_mean = comm_df['Population in private households'].mean()\n",
    "pop_std = comm_df['Population in private households'].std()\n",
    "\n",
    "\n",
    "medinc_mean = comm_df[\"Median household income of private households\"].mean()\n",
    "medinc_std = comm_df[\"Median household income of private households\"].std()\n",
    "\n",
    "low_mean = comm_df['Population in private households to whom low income concepts are applicable (Number in low income)'].mean()\n",
    "low_std = comm_df['Population in private households to whom low income concepts are applicable (Number in low income)'].std()\n",
    "\n",
    "trans_mean = ((comm_df['Employed']/comm_df[\"Employed labour force aged 15 years and over in private households\"])*comm_df['Public transit']).mean()\n",
    "trans_std = ((comm_df['Employed']/comm_df[\"Employed labour force aged 15 years and over in private households\"])*comm_df['Public transit']).std()\n",
    "\n",
    "rent_mean = (comm_df['Per cent households with income spending 30% or more total income on shelter (Renter)']*comm_df['Private households with total income greater than zero (Renter)']).mean()\n",
    "rent_std = (comm_df['Per cent households with income spending 30% or more total income on shelter (Renter)']*comm_df['Private households with total income greater than zero (Renter)']).std()\n",
    "\n",
    "seniors_mean = comm_df['65 to 84 years'].mean()\n",
    "seniors_std = comm_df['65 to 84 years'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = comm_df.shape\n",
    "z_rows_to_append = []\n",
    "for c in range(row):\n",
    "    community = comm_df['Community Name'][c]\n",
    "    \n",
    "    pop = comm_df['Population in private households'][c]\n",
    "    # pop_ss = (pop-pop_max)/(pop_max-pop_min)\n",
    "    z_pop_score = (pop-pop_mean)/pop_std\n",
    "    \n",
    "    med = comm_df['Median household income of private households'][c]\n",
    "    # med_ss = (med-medinc_max)/(medinc_max-medinc_min)\n",
    "    z_med_score = (med-medinc_mean)/medinc_std\n",
    "    \n",
    "    trans = ((comm_df['Employed']/comm_df[\"Employed labour force aged 15 years and over in private households\"])*comm_df['Public transit'])[c]\n",
    "    # trans_ss = (trans-trans_max)/(trans_max-trans_min)\n",
    "    z_trans_score = (trans-trans_mean)/trans_std\n",
    "    \n",
    "    rent = (comm_df['Per cent households with income spending 30% or more total income on shelter (Renter)']*comm_df['Private households with total income greater than zero (Renter)'])[c]\n",
    "    # rent_ss = (rent-rent_max)/(rent_max-rent_min)\n",
    "    z_rent_score = (rent-rent_mean)/rent_std\n",
    "    \n",
    "    low = comm_df['Population in private households to whom low income concepts are applicable (Number in low income)'][c]\n",
    "    # low_ss = (low-low_max)/(low_max-low_min)\n",
    "    z_low_score = (low-low_mean)/low_std\n",
    "\n",
    "    sen = comm_df['65 to 84 years'][c]\n",
    "    z_seniors_score = (sen-seniors_mean)/seniors_std\n",
    "\n",
    "    z_result = z_trans_score+z_rent_score+z_low_score-z_med_score+z_seniors_score\n",
    "    # z_result = z_trans_score+z_rent_score+z_low_score+z_seniors_score\n",
    "\n",
    "    column_df = {\"Community Name\": community, \"Z Score\": z_result}\n",
    "    columns_df = {\"Community Name\": community, \"Low Income Index\": z_low_score, \"Seniors Index\": z_seniors_score, \"Public Transit Index\": z_trans_score, \"Rent Index\": z_rent_score, \"Median Income\": z_med_score}\n",
    "    z_rows_to_append.append(column_df)\n",
    "\n",
    "\n",
    "Z_index_df = pd.DataFrame(z_rows_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_index_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_max = Z_index_df['Z Score'].max()\n",
    "z_min = Z_index_df['Z Score'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_max)\n",
    "print(z_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = Z_index_df.shape\n",
    "z_ss_rows = []\n",
    "for c in range(row):\n",
    "    community = Z_index_df[\"Community Name\"][c]\n",
    "    z_score = Z_index_df['Z Score'][c]\n",
    "\n",
    "    z_ss_result = (z_score-z_min)/(z_max-z_min)\n",
    "\n",
    "    column_df = {\"Community Name\": community, \"Z Score\": z_ss_result}\n",
    "    z_ss_rows.append(column_df)\n",
    "    \n",
    "z_ss_index_df = pd.DataFrame(z_ss_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ss_index_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(z_ss_index_df, output_folder_path, 'Z Standardized Demand Index.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program To Visualize ArcGis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_link = \"https://ucalgary.maps.arcgis.com\"\n",
    "gis_user = \"sbasit_ucalgary\"\n",
    "gis_pass = \"Sa5nar9(\"\n",
    "gis_key = \"AAPK049cf86d96f4462ba33f8b661792d2f0z748Z0jNex7rIOx45MLoRtWEUFk5CElu0-Obz_3bxUwj9_Q8MI398NcMkS9xWe5F\"\n",
    "stop_freq_id = \"ec5537fa5cca45a7ba53f3d70a961c9e\"\n",
    "comm_boundary_id = \"23864b8797424379951a0d4117034bdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gis = GIS(gis_link,gis_user,gis_pass,gis_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_content = my_gis.content.search(query=\"owner:\"+my_gis.users.me.username+\" & Title: Z*\", item_type='Feature *')\n",
    "my_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "You do not have permissions to access this resource or perform this operation.\n(Error Code: 403)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stop_map \u001b[38;5;241m=\u001b[39m \u001b[43mmy_gis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomm_boundary_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# stop_map.add_layer(comm_map)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# map.add_layer(comm_boundary_id)\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arcgis/gis/__init__.py:7277\u001b[0m, in \u001b[0;36mContentManager.get\u001b[0;34m(self, itemid)\u001b[0m\n\u001b[1;32m   7275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   7276\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7277\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   7279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   7280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Item(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gis, itemid, item)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arcgis/gis/__init__.py:7267\u001b[0m, in \u001b[0;36mContentManager.get\u001b[0;34m(self, itemid)\u001b[0m\n\u001b[1;32m   7254\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7255\u001b[0m \u001b[38;5;124;03mThe ``get`` method returns the :class:`~arcgis.gis.Item` object for the specified itemid.\u001b[39;00m\n\u001b[1;32m   7256\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7264\u001b[0m \u001b[38;5;124;03m    The item object if the item is found, None if the item is not found.\u001b[39;00m\n\u001b[1;32m   7265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 7267\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_portal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitemid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m re:\n\u001b[1;32m   7269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem does not exist or is inaccessible\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arcgis/gis/_impl/_portalpy.py:1425\u001b[0m, in \u001b[0;36mPortal.get_item\u001b[0;34m(self, itemid)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, itemid: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the item information for the specified item.\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m \n\u001b[1;32m   1364\u001b[0m \u001b[38;5;124;03m    Arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;124;03m        ================  ========================================================\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent/items/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mitemid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_postdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arcgis/gis/_impl/_con/_connection.py:1524\u001b[0m, in \u001b[0;36mConnection.post\u001b[0;34m(self, path, params, files, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_raw_response:\n\u001b[1;32m   1523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n\u001b[0;32m-> 1524\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_json\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforce_bytes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arcgis/gis/_impl/_con/_connection.py:1000\u001b[0m, in \u001b[0;36mConnection._handle_response\u001b[0;34m(self, resp, file_name, out_path, try_json, force_bytes, ignore_error_key)\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    999\u001b[0m         errorcode \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1000\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_json_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrorcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arcgis/gis/_impl/_con/_connection.py:1023\u001b[0m, in \u001b[0;36mConnection._handle_json_error\u001b[0;34m(self, error, errorcode)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                 \u001b[38;5;66;03m# _log.error(errordetail)\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m errormessage \u001b[38;5;241m=\u001b[39m errormessage \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(Error Code: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(errorcode) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1023\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(errormessage)\n",
      "\u001b[0;31mException\u001b[0m: You do not have permissions to access this resource or perform this operation.\n(Error Code: 403)"
     ]
    }
   ],
   "source": [
    "stop_map = my_gis.content.get(comm_boundary_id)\n",
    "\n",
    "# stop_map.add_layer(comm_map)\n",
    "# map.add_layer(comm_boundary_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapView(layout=Layout(height='400px', width='100%'))\n"
     ]
    }
   ],
   "source": [
    "print(comm_map)\n",
    "# my_gis.map(stop_freq_id)\n",
    "# comm_map\n",
    "# print(\"echo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Multipolygon Data To Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.getcwd()+\"/Data Sets/Analysis Data/\"\n",
    "comm_file = \"Community Profiles Compiled.xlsx\"\n",
    "bound_file = \"Boundraries_Data_by_Community .csv\"\n",
    "z_index_file = \"Z Standardized Demand Index.csv\"\n",
    "census_file = \"Census by Community 2019_20240401.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_data = pd.read_excel(folder_path+comm_file)\n",
    "comm_bound = gpd.read_file(folder_path+census_file)\n",
    "z_index = pd.read_csv(folder_path+z_index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_bound.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_bound_lower = comm_bound.copy()\n",
    "comm_bound_lower['name'] = comm_bound_lower['name'].str.lower()\n",
    "comm_data_lower = comm_data.copy()\n",
    "comm_data_lower['Community Name'] = comm_data_lower['Community Name'].str.lower()\n",
    "comm_z_lower = z_index.copy()\n",
    "comm_z_lower[\"Community Name\"] = comm_z_lower['Community Name'].str.lower()\n",
    "\n",
    "# Merge the DataFrames based on the lower case names\n",
    "# merged_data = pd.merge(comm_data_lower, comm_bound_lower, left_on='Community Name', right_on='NAME', how='inner')\n",
    "merged_data = pd.merge(comm_z_lower, comm_bound_lower, how='left', left_on='Community Name', right_on='name')\n",
    "\n",
    "# Convert back to original case if needed\n",
    "merged_data['name'] = comm_bound['name']  # Assuming you want to keep the original case for boundary names\n",
    "merged_data['Community Name'] = comm_data['Community Name']  # Assuming you want to keep the original case for community names\n",
    "\n",
    "# Now merged_data contains the rows where the names match, regardless of case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set_data = merged_data[[\"Community Name\",\"Z Score\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set_data.head()\n",
    "type(sub_set_data['geometry'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_data = gpd.GeoDataFrame(sub_set_data, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_data.to_file(folder_path+\"Community_Z_Boundary.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data Sets For Calculating Supply Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtfs_path = os.getcwd()+\"/Data Sets/CT_GTFS.zip\"\n",
    "# feed = Feed(gtfs_path, start_date = \"2024-02-19\", end_date = \"2024-02-23\", time_windows=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24])\n",
    "feed = Feed(gtfs_path, start_date = \"2024-02-19\", end_date = \"2024-02-23\", time_windows=[0,5,6,9,15,18,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = feed.routes\n",
    "trips = feed.trips\n",
    "stops = feed.stops\n",
    "stop_times = feed.stop_times\n",
    "shapes = feed.shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed = Feed(gtfs_path,start_date=\"2024-02-17\", end_date=\"2024-02-17\")\n",
    "stop_freq = feed.stops_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = [3641, 3816, 3817, 3960, 4155, 4934, 6801, 6802, 6803, 6804, 6805, 6806, 6807, 6815, 6816, 6817, 6818, 6819, 6820, 6822, 6823, 6824, 6825, 6827, 6828, 6829, 6830, 6831, 8556, 8557, 8558, 8559, 8560, 8561, 8562, 8563, 8564, 8565, 8566, 9261, 9262, 9263, 9264, 9387, 9390, 9391, 9392, 3627, 3628, 3629, 3630, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3638, 3639, 6747, 6808, 6809, 6810, 6811, 6812, 6813, 6814, 6825, 6831, 8567, 8568, 8569, 8570, 8571, 8572, 9385, 9396, 9781, 9896, 9897, 2350, 2376, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 3495, 5701, 5703, 5718, 5730, 5731, 5732, 5734, 5789, 6048, 6724, 6846, 7281, 7759, 7762, 7763, 7764, 7881, 7892, 8157, 8161, 8162, 8163, 8215, 9400, 9407, 9409, 9430, 9439, 9617, 3368, 3370, 3371, 3372, 3380, 3381, 3382, 3383, 3384, 3751, 3761, 4567, 4568, 4582, 4583, 5147, 5385, 5630, 5752, 5754, 5767, 5769, 6099, 6110, 6111, 6586, 6982, 8038, 8368, 9174, 9178, 9828, 2469, 2486, 2487, 2488, 2489, 2498, 3371, 3531, 3744, 3745, 3746, 3747, 3748, 3755, 3756, 3764, 3765, 3766, 3767, 3870, 5762, 5763, 6119, 6982, 9453, 9935, 2178, 2180, 2234, 2299, 2788, 3387, 3388, 3389, 3390, 3391, 3392, 3886, 4352, 5057, 7380, 8271, 8653, 8832, 9802, 9805, 9807, 9808, 9809, 9810, 9815, 9816, 9817, 9818, 9820, 9821]\n",
    "stop_list_str = [str(x) for x in stop_list]\n",
    "# stop_freq.loc[stop_freq[\"stop_id\"].isin(stop_list_str)].sort_values(by='stop_id').to_excel(\"PTN_stop_frequency.xlsx\")\n",
    "stop_freq.loc[stop_freq[\"stop_id\"].isin(stop_list_str)].sort_values(by='stop_id')\n",
    "# type(stop_freq[\"stop_id\"][1])\n",
    "# stop_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_freq = feed.lines_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_freq.loc[line_freq[\"route_name\"].str.contains(\"Line|MAX\")].sort_values(by=['window']).to_excel(\"Lines_Frequency.xlsx\")\n",
    "ptn = line_freq.loc[line_freq[\"route_name\"].str.contains(\"Line|MAX\")].sort_values(by=['window'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_rush = '6:00-9:00'\n",
    "evening_rush = '15:00-18:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_hour_performance = ptn.loc[ptn['window'].str.contains(morning_rush+\"|\"+evening_rush)].sort_values(by=['route_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptn.to_excel('Lines_Frequency.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_trips = ptn.groupby('route_name')['ntrips'].sum()\n",
    "rush_hour_performance.groupby('route_id')['ntrips'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_hour_performance.groupby('route_id')['min_per_trip'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_hour_performance.groupby('route_id')['min_per_trip'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize through Kepler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = Feed(gtfs_path,start_date=\"2024-02-17\", end_date=\"2024-02-17\")\n",
    "\n",
    "feed.stop_times.fillna('', inplace=True)\n",
    "feed.trips.fillna('', inplace=True)\n",
    "# Repeat for other DataFrame attributes as needed\n",
    "\n",
    "# Now call get_segments_freq()\n",
    "segments_freq = feed.segments_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_segments = segments_freq.loc[segments_freq[\"route_name\"].str.contains(\"MAX|Line\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = kpl.KeplerGl(data=dict(data = filtered_segments, name = \"PTN_segments\"), config= ptn_config, height = 750)\n",
    "map.add_data(gpd_data, name=\"Community\")\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptn_config = map.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Frequency and Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd()+\"/Data Sets/Analysis Data/\"\n",
    "current_supply_data = \"Supplyside588.xlsx\"\n",
    "future_supply_data = \"Supplyside588 - With future stops Updated.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_trips = 193\n",
    "blue_freq = 8.9333\n",
    "red_trips = 444\n",
    "red_freq = 6.7\n",
    "orange_trips = 98\n",
    "orange_freq = 7.0833\n",
    "teal_trips = 65\n",
    "teal_freq = 15.6923\n",
    "yellow_trips = 75\n",
    "yellow_freq = 9.75\n",
    "purple_trips = 127\n",
    "purple_freq = 20.5172\n",
    "\n",
    "bus_capacity = 65\n",
    "train_capacity = 600\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_df = pd.read_excel(data_path+current_supply_data, sheet_name=\"Frequency Index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc['Community'] = supply_df['Community']\n",
    "sup_fc['Blue Trips'] = supply_df['Blue']\n",
    "sup_fc['Blue Freq'] = supply_df['Blue']\n",
    "sup_fc['Red Trips'] = supply_df[\"Red\"]\n",
    "sup_fc['Red Freq'] = supply_df[\"Red\"]\n",
    "sup_fc['Teal Trips'] = supply_df[\"Teal\"]\n",
    "sup_fc['Teal Freq'] = supply_df[\"Teal\"]\n",
    "sup_fc['Orange Trips'] = supply_df[\"Orange\"]\n",
    "sup_fc['Orange Freq'] = supply_df[\"Orange\"]\n",
    "sup_fc['Yellow Trips'] = supply_df[\"Yellow\"]\n",
    "sup_fc['Yellow Freq'] = supply_df[\"Yellow\"]\n",
    "sup_fc['Purple Trips'] = supply_df[\"Purple\"]\n",
    "sup_fc['Purple Freq'] = supply_df[\"Purple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.loc[(sup_fc['Blue Trips'] != 0),'Blue Trips'] = blue_trips\n",
    "sup_fc.loc[(sup_fc['Blue Freq'] != 0),'Blue Freq'] = blue_freq\n",
    "sup_fc.loc[(sup_fc['Red Trips'] != 0),'Red Trips'] = red_trips\n",
    "sup_fc.loc[(sup_fc['Red Freq'] != 0),'Red Freq'] = red_freq\n",
    "sup_fc.loc[(sup_fc['Orange Trips'] != 0),'Orange Trips'] = orange_trips\n",
    "sup_fc.loc[(sup_fc['Orange Freq'] != 0),'Orange Freq'] = orange_freq\n",
    "sup_fc.loc[(sup_fc['Yellow Trips'] != 0),'Yellow Trips'] = yellow_trips\n",
    "sup_fc.loc[(sup_fc['Yellow Freq'] != 0),'Yellow Freq'] = yellow_freq\n",
    "sup_fc.loc[(sup_fc['Teal Trips'] != 0),'Teal Trips'] = teal_trips\n",
    "sup_fc.loc[(sup_fc['Teal Freq'] != 0),'Teal Freq'] = teal_freq\n",
    "sup_fc.loc[(sup_fc['Purple Trips'] != 0),'Purple Trips'] = purple_trips\n",
    "sup_fc.loc[(sup_fc['Purple Freq'] != 0),'Purple Freq'] = purple_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'Community' and 'Community Name' columns\n",
    "merged_data = pd.merge(sup_fc, comm_data, left_on='Community', right_on='Community Name', how='right')\n",
    "\n",
    "# Update the 'Population' column in sup_fc with the corresponding values from comm_data\n",
    "sup_fc['Population'] = merged_data['Population in private households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_col = sup_fc.filter(like=\"Freq\")\n",
    "sup_fc['Total Freq'] = freq_col.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_col = sup_fc.filter(like=\"Trips\")\n",
    "train_col = trip_col.filter(regex=\"Blue|Red\")\n",
    "bus_col = trip_col.filter(regex=\"Orange|Teal|Yellow|Purple\")\n",
    "pop_col = sup_fc.filter(like=\"Population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sup_fc[\"Capacity Index\"] = ((train_col.sum(axis=1)*train_capacity)+(bus_col.sum(axis=1)*bus_capacity))/pop_col.sum(axis=1)\n",
    "sup_fc['Sum Train Capacity'] = train_col.sum(axis=1)*train_capacity\n",
    "sup_fc['Sum Bus Capacity'] = bus_col.sum(axis=1)*bus_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc[\"Capacity Index\"] = (sup_fc['Sum Train Capacity']+sup_fc['Sum Bus Capacity'])/pop_col.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = min(sup_fc[\"Total Freq\"])\n",
    "max_freq = max(sup_fc[\"Total Freq\"])\n",
    "min_cap = min(sup_fc['Capacity Index'])\n",
    "max_cap = max(sup_fc['Capacity Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_freq, max_freq, min_cap, max_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc['SS Freq'] = (sup_fc['Total Freq']-min_freq)/(max_freq-min_freq)\n",
    "sup_fc['SS Cap'] = (sup_fc['Capacity Index']-min_cap)/(max_cap-min_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.loc[sup_fc[\"Capacity Index\"]==max_cap].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.to_csv(data_path+'Current_Freq_Cap.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut_sup_df = pd.read_excel(data_path+future_supply_data, sheet_name = 'F.Frequ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc['Community'] = fut_sup_df['Community']\n",
    "sup_fc['Blue Trips'] = fut_sup_df['Blue']\n",
    "sup_fc['Blue Freq'] = fut_sup_df['Blue']\n",
    "sup_fc['Red Trips'] = fut_sup_df[\"Red\"]\n",
    "sup_fc['Red Freq'] = fut_sup_df[\"Red\"]\n",
    "sup_fc['Green Trips'] = fut_sup_df[\"Green\"]\n",
    "sup_fc['Green Freq'] = fut_sup_df[\"Green\"]\n",
    "sup_fc['Teal Trips'] = fut_sup_df[\"Teal\"]\n",
    "sup_fc['Teal Freq'] = fut_sup_df[\"Teal\"]\n",
    "sup_fc['Orange Trips'] = fut_sup_df[\"Orange\"]\n",
    "sup_fc['Orange Freq'] = fut_sup_df[\"Orange\"]\n",
    "sup_fc['Yellow Trips'] = fut_sup_df[\"Yellow\"]\n",
    "sup_fc['Yellow Freq'] = fut_sup_df[\"Yellow\"]\n",
    "sup_fc['Purple Trips'] = fut_sup_df[\"Purple\"]\n",
    "sup_fc['Purple Freq'] = fut_sup_df[\"Purple\"]\n",
    "sup_fc['East Gray Trips'] = fut_sup_df[\"Teal\"]\n",
    "sup_fc['East Gray Freq'] = fut_sup_df[\"Teal\"]\n",
    "sup_fc['West Gray Trips'] = fut_sup_df[\"Teal\"]\n",
    "sup_fc['West Gray Freq'] = fut_sup_df[\"Teal\"]\n",
    "sup_fc['Future Brentwood Trips'] = fut_sup_df[\"Teal\"]\n",
    "sup_fc['Future Brentwood Freq'] = fut_sup_df[\"Teal\"]\n",
    "sup_fc['Future Tuscany Trips'] = fut_sup_df[\"Teal\"]\n",
    "sup_fc['Future Tuscany Freq'] = fut_sup_df[\"Teal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sup_fc.shape)\n",
    "sup_fc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.loc[(sup_fc['Blue Trips'] != 0),'Blue Trips'] = blue_trips\n",
    "sup_fc.loc[(sup_fc['Blue Freq'] != 0),'Blue Freq'] = blue_freq\n",
    "sup_fc.loc[(sup_fc['Red Trips'] != 0),'Red Trips'] = red_trips\n",
    "sup_fc.loc[(sup_fc['Red Freq'] != 0),'Red Freq'] = red_freq\n",
    "sup_fc.loc[(sup_fc['Orange Trips'] != 0),'Orange Trips'] = orange_trips\n",
    "sup_fc.loc[(sup_fc['Orange Freq'] != 0),'Orange Freq'] = orange_freq\n",
    "sup_fc.loc[(sup_fc['Yellow Trips'] != 0),'Yellow Trips'] = yellow_trips\n",
    "sup_fc.loc[(sup_fc['Yellow Freq'] != 0),'Yellow Freq'] = yellow_freq\n",
    "sup_fc.loc[(sup_fc['Teal Trips'] != 0),'Teal Trips'] = teal_trips\n",
    "sup_fc.loc[(sup_fc['Teal Freq'] != 0),'Teal Freq'] = teal_freq\n",
    "sup_fc.loc[(sup_fc['Purple Trips'] != 0),'Purple Trips'] = purple_trips\n",
    "sup_fc.loc[(sup_fc['Purple Freq'] != 0),'Purple Freq'] = purple_freq\n",
    "sup_fc.loc[(sup_fc['Green Trips'] != 0), 'Green Trips'] = red_trips\n",
    "sup_fc.loc[(sup_fc['Green Freq'] != 0), 'Green Freq'] = red_freq\n",
    "sup_fc.loc[(sup_fc['East Gray Trips'] != 0), 'East Gray Trips']  = teal_trips\n",
    "sup_fc.loc[(sup_fc['East Gray Freq'] != 0), 'East Gray Freq']  = teal_freq\n",
    "sup_fc.loc[(sup_fc['West Gray Trips'] != 0), 'West Gray Trips'] = teal_trips\n",
    "sup_fc.loc[(sup_fc['West Gray Freq'] != 0), 'West Gray Freq']  = teal_freq\n",
    "sup_fc.loc[(sup_fc['Future Brentwood Trips'] !=0), 'Future Brentwood Trips'] = teal_trips\n",
    "sup_fc.loc[(sup_fc['Future Brentwood Freq'] !=0), 'Future Brentwood Freq'] = teal_freq\n",
    "sup_fc.loc[(sup_fc['Future Tuscany Trips'] !=0), 'Future Tuscany Trips'] = teal_trips\n",
    "sup_fc.loc[(sup_fc['Future Tuscany Freq'] !=0), 'Future Tuscany Freq'] = teal_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sup_fc.shape)\n",
    "sup_fc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'Community' and 'Community Name' columns\n",
    "merged_data = pd.merge(sup_fc, comm_data, left_on='Community', right_on='Community Name', how='right')\n",
    "\n",
    "# Update the 'Population' column in sup_fc with the corresponding values from comm_data\n",
    "sup_fc['Population'] = merged_data['Population in private households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_col = sup_fc.filter(like=\"Freq\")\n",
    "trip_col = sup_fc.filter(like=\"Trips\")\n",
    "train_col = trip_col.filter(regex=\"Blue|Red|Green\")\n",
    "bus_col = trip_col.filter(regex=\"Orange|Teal|Yellow|Purple|Gray|Future\")\n",
    "pop_col = sup_fc.filter(like=\"Population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc['Total Freq'] = freq_col.sum(axis=1)\n",
    "sup_fc['Sum Train Capacity'] = train_col.sum(axis=1)*train_capacity\n",
    "sup_fc['Sum Bus Capacity'] = bus_col.sum(axis=1)*bus_capacity\n",
    "sup_fc[\"Capacity Index\"] = (sup_fc['Sum Train Capacity']+sup_fc['Sum Bus Capacity'])/pop_col.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = min(sup_fc[\"Total Freq\"])\n",
    "max_freq = max(sup_fc[\"Total Freq\"])\n",
    "min_cap = min(sup_fc['Capacity Index'])\n",
    "max_cap = max(sup_fc['Capacity Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc['SS Freq'] = (sup_fc['Total Freq']-min_freq)/(max_freq-min_freq)\n",
    "sup_fc['SS Cap'] = (sup_fc['Capacity Index']-min_cap)/(max_cap-min_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sup_fc.shape)\n",
    "sup_fc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_fc.to_csv(data_path+'Future_Freq_Cap.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
